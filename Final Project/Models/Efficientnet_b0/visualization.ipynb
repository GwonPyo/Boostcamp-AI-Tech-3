{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5105dc79-8bb3-40d3-b2a3-027722f94918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference : https://github.com/yaleCat/Grad-CAM-pytorch\n",
    "\n",
    "import sys\n",
    "sys.path.append('/')\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torchvision import models\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from grad_cam import GradCam,GuidedBackpropReLUModel,show_cam_on_image,show_gbs,preprocess_image\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4849ec8-fdca-471b-aced-971ecd26234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(42)\n",
    "if device == 'cuda':\n",
    "  torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cf809e3-3d52-424c-8b3d-7a22d00f8c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_path = '/opt/ml/dataset/valid/JPEGImages'\n",
    "file_list = os.listdir(valid_path)\n",
    "image_list = []\n",
    "\n",
    "for file in file_list:\n",
    "    if '.jpg' in file:\n",
    "        image_list.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07275cef-0592-4e75-8877-5a604810c506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "model = EfficientNet.from_pretrained('efficientnet-b0', num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a884d812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = './epoch30/remove_background/model.pth'\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b78c6e73-ab88-4459-9435-c6ce1b6fc852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of blocks : 16\n"
     ]
    }
   ],
   "source": [
    "num_blocks = len(model._blocks)\n",
    "print(f'num of blocks : {num_blocks}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dadec81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from grad_cam import GradCam,GuidedBackpropReLUModel,show_cam_on_image,show_gbs,preprocess_image\n",
    "\n",
    "idx = 300\n",
    "\n",
    "# 마지막 레이어를 보도록 (원하는 레이어가 있으면 번호를 적어주세요. ex) ['19', '32']\n",
    "target_layer_names = [str(num_blocks - 1)]\n",
    "\n",
    "img = cv2.imread('./my_face.PNG', 1)\n",
    "img_size = (256,256)\n",
    "img = np.float32(cv2.resize(img, img_size))/255\n",
    "inputs = preprocess_image(img)\n",
    "grad_cam = GradCam(\n",
    "    model=model,\n",
    "    blob_name = '_blocks',\n",
    "    target_layer_names=target_layer_names,\n",
    "    use_cuda=True,\n",
    "    img_size=img_size)\n",
    "    \n",
    "# 예측값 비교\n",
    "out = model(inputs.to(device))\n",
    "pred = torch.argmax(out, dim=-1)[0]\n",
    "print(inputs.shape)\n",
    "key = 'oil' # 항목\n",
    "json_path = os.path.join(valid_path, image_list[idx].replace('jpg', 'json'))\n",
    "with open(json_path, \"r\") as json_file:   # json 파일에 접근하여 json 파일을 불러온다.\n",
    "    img_json = json.load(json_file)             \n",
    "    \n",
    "label = img_json[key]\n",
    "\n",
    "print(f'predict: {pred}, gt: {label}')\n",
    "\n",
    "# If None, returns the map for the highest scoring category.\n",
    "# Otherwise, targets the requested index.\n",
    "target_index = pred\n",
    "mask_dic = grad_cam(inputs, target_index)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=len(target_layer_names) + 1, figsize=(10*(len(target_layer_names) + 1), 10))\n",
    "axes[0].imshow(img[:, :, ::-1])\n",
    "axes[0].axis('off')\n",
    "\n",
    "for i, (name, mask) in enumerate(mask_dic.items()):\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * (1-mask)), cv2.COLORMAP_JET)\n",
    "    heatmap = np.float32(heatmap) / 255\n",
    "    heatmap[:,:,2] = 0\n",
    "    cam = heatmap*0.3 + np.float32(img[:,:,::-1])\n",
    "    cam = cam / np.max(cam)\n",
    "\n",
    "    axes[i + 1].imshow(cam)\n",
    "    axes[i + 1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
