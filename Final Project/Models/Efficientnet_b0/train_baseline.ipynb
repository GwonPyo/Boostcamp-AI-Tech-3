{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Import Header </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from rembg import remove\n",
    "\n",
    "import torch\n",
    "import timm\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from torchsampler import ImbalancedDatasetSampler\n",
    "\n",
    "import wandb\n",
    "# import mlflow\n",
    "# import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mngp9441\u001b[0m (\u001b[33martlab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/opt/ml/efficient_net_b4/wandb/run-20220603_025224-279guzzv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/artlab/oil_base_dataset/runs/279guzzv\" target=\"_blank\">fine-pyramid-14</a></strong> to <a href=\"https://wandb.ai/artlab/oil_base_dataset\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/artlab/oil_base_dataset/runs/279guzzv?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f0e21b96370>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project='oil_base_dataset', entity='artlab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Set Device </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "if device == 'cuda':\n",
    "  torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Set Hyper Parameters </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "total_epoch = 100\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Define Dataset / DataLoader </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'oil'                                                             # 학습하고자 하는 category를 설정한다. ('oil','sensitive','pigmentation','wrinkle', 'hydration' 중 택1) / oil기준 30초 소요\n",
    "\n",
    "train_images = []                                                       # 먼저 학습 데이터에 대한 이미지와 라벨을 모으기 위해 리스트 두 개를 선언한다.\n",
    "train_labels = []\n",
    "valid_images = []                                                       # valid셋에 대해서도 동일한 작업을 위해 두 개의 리스트를 선언한다.\n",
    "valid_labels = []\n",
    "\n",
    "train_path = '../dataset/train' \n",
    "with open(os.path.join(train_path, \"annotations.json\"), \"r\") as json_file:\n",
    "    train_ann = json.load(json_file)\n",
    "images_info = train_ann['images']\n",
    "\n",
    "for image_info in images_info:\n",
    "    image_name = image_info['file_name']                                # 이미지 파일의 이름을 가져온다.\n",
    "    file_name = image_name.replace('jpg', 'json')                       # 이미지에 대한 라벨링 json파일의 이름을 저장한다. (.jpg를 .json으로 변경하면 된다.)\n",
    "\n",
    "    with open(os.path.join(train_path, file_name), \"r\") as json_file:   # json 파일에 접근하여 json 파일을 불러온다.\n",
    "        img_json = json.load(json_file)             \n",
    "    \n",
    "    label = img_json[key]                                               # 학습하고자 하는 category의 라벨을 저장한다.\n",
    "    \n",
    "    if label < 0: continue                                              # 라벨이 -2, -1인 경우 학습에서 제외하여야 한다.\n",
    "\n",
    "    image_path = os.path.join(train_path, image_name)                   # 이미지 경로를 불러온다.\n",
    "    image = cv2.imread(image_path)                                      # 이미지를 불러오고 BGR을 RGB로 변경해준다.\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    train_images.append(image)\n",
    "    train_labels.append(label)\n",
    "\n",
    "    if label == 4:\n",
    "        valid_images.append(image)\n",
    "        valid_labels.append(label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_path = '../dataset/valid' \n",
    "with open(os.path.join(valid_path, \"annotations.json\"), \"r\") as json_file:\n",
    "    valid_ann = json.load(json_file)\n",
    "images_info = valid_ann['images']\n",
    "\n",
    "for image_info in images_info:\n",
    "    image_name = image_info['file_name']                                # 이미지 파일의 이름을 가져온다.\n",
    "    file_name = image_name.replace('jpg', 'json')                       # 이미지에 대한 라벨링 json파일의 이름을 저장한다. (.jpg를 .json으로 변경하면 된다.)\n",
    "\n",
    "    with open(os.path.join(valid_path, file_name), \"r\") as json_file:   # json 파일에 접근하여 json 파일을 불러온다.\n",
    "        img_json = json.load(json_file)             \n",
    "    \n",
    "    label = img_json[key]                                               # 학습하고자 하는 category의 라벨을 저장한다.\n",
    "    \n",
    "    if label < 0: continue                                              # 라벨이 -2, -1인 경우 학습에서 제외하여야 한다.\n",
    "    \n",
    "    image_path = os.path.join(valid_path, image_name)                   # 이미지 경로를 불러온다.\n",
    "    image = cv2.imread(image_path)                                      # 이미지를 불러오고 BGR을 RGB로 변경해준다.\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
    "    \n",
    "    valid_images.append(image)\n",
    "    valid_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, valid dataset class를 선언한다.\n",
    "class TrainDataset(Dataset):\n",
    "  def __init__(self, images, labels, transform=None):\n",
    "    self.images = images\n",
    "    self.labels = labels\n",
    "    self.transform = transform\n",
    "  def __len__(self):\n",
    "    return len(self.labels)\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "    image = self.images[index]\n",
    "    \n",
    "    if self.transform is not None:\n",
    "      image = self.transform(image=image)['image']\n",
    "    \n",
    "    label = self.labels[index]\n",
    "    return image, label\n",
    "\n",
    "class ValidDataset(Dataset):\n",
    "  def __init__(self, images, labels, transform=None):\n",
    "    self.images = images\n",
    "    self.labels = labels\n",
    "    self.transform = transform\n",
    "  def __len__(self):\n",
    "    return len(self.labels)\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "    image = self.images[index]\n",
    "\n",
    "    if self.transform is not None:\n",
    "      image = self.transform(image=image)['image']\n",
    "\n",
    "    label = self.labels[index]\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train과 valid에 사용할 transform을 선언한다.\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(784, 784), \n",
    "    A.CenterCrop(512, 512),\n",
    "    # A.RandomResizedCrop(p=1.0, height=512, width=512, scale=(0.7, 1.0)),\n",
    "    A.ColorJitter(0.5, 0.5, 0.5, 0.25, p=0.5),\n",
    "    A.OpticalDistortion(distort_limit=0.1, p=0.5),\n",
    "    A.RGBShift(p=0.5 , r_shift_limit=(-20, 20), g_shift_limit=(-20, 20), b_shift_limit=(-20, 20)),\n",
    "    # A.ISONoise(p=0.7, intensity=(0.0, 0.5), color_shift=(0.0, 0.1)),\n",
    "    # A.RandomBrightness(p=0.7, limit=(-0.2, 0.2)),\n",
    "    \n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    \n",
    "    A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "valid_transform = A.Compose([\n",
    "    A.Resize(784, 784), \n",
    "    A.CenterCrop(512, 512),\n",
    "    # A.RandomResizedCrop(p=1.0, height=512, width=512, scale=(0.7, 1.0)),\n",
    "    # A.RandomBrightness(p=0.5),\n",
    "    # A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.15, p=0.5),\n",
    "    A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, valid dataset을 선언한다.\n",
    "train_dataset = TrainDataset(train_images, train_labels, train_transform)\n",
    "valid_dataset = ValidDataset(valid_images, valid_labels, valid_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train. valid loader를 선언한다.\n",
    "train_loader = DataLoader(train_dataset, sampler=ImbalancedDatasetSampler(train_dataset, labels=train_dataset.labels), batch_size = batch_size, drop_last=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size = batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Define Model & Train </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "model = EfficientNet.from_pretrained('efficientnet-b0').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "in_features = model._fc.in_features\n",
    "model._fc = nn.Linear(in_features=in_features, out_features=5, bias=True).to(device)\n",
    "\n",
    "wandb.watch(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, class_num, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.class_num = class_num\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)                                   # prediction한 값을 softmax 함수에 통과시킨다.\n",
    "        \n",
    "        with torch.no_grad():               \n",
    "            new_label = torch.zeros_like(pred)                                  # class 개수만큼 0을 채운 tensor를 만든다.\n",
    "            new_label.fill_(self.smoothing / (self.class_num - 1))              # 알맞은 smoothing 값을 넣어준다.\n",
    "            new_label.scatter_(1, target.data.unsqueeze(1), self.confidence)    # 기존 정답 라벨에 해당하는 인덱스에는 confidence값을 넣어준다.\n",
    "            \n",
    "        '''\n",
    "        새로운 정답 라벨(텐서)와 softmax를 통과시킨 값을 곱한 값에 평균을 취하면 해당 이미지에 대한 loss값이 나온다.\n",
    "        따라서 해당 loss값들을 모두 평균낸다.\n",
    "        '''\n",
    "        return torch.mean(torch.sum(-new_label * pred, dim=self.dim))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "criterion = LabelSmoothingLoss(5, 0.1).to(device)\n",
    "# criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metric:\n",
    "    def __init__(self, num_classes=5):\n",
    "        self.num_classes = num_classes\n",
    "        self.matrix = [[0]*self.num_classes for _ in range(self.num_classes)]\n",
    "        self.weights = [0]*(self.num_classes - 2) + [0.5, 1, 0.5] + [0]*(self.num_classes - 2)\n",
    "        self.penalty = [-0.5 * i for i in range(self.num_classes - 2, 0, -1)] + [0.5, 1, 0.5] + [-0.5 * i for i in range(1, self.num_classes - 1)]\n",
    "        self.epsilon = 1e-7\n",
    "\n",
    "    def add_data(self, preds, labels):\n",
    "        size = len(labels)\n",
    "        preds = torch.argmax(preds, dim=-1)\n",
    "        for s in range(size):\n",
    "            self.matrix[int(labels[s])][int(preds[s])] += 1\n",
    "\n",
    "    def _precision(self):\n",
    "        res = []\n",
    "        for i in range(self.num_classes):\n",
    "            temp = []\n",
    "            for j in range(self.num_classes):\n",
    "                temp.append(self.matrix[j][i])\n",
    "            res.append(temp[i] / (sum(temp) + self.epsilon))\n",
    "        return res\n",
    "\n",
    "    def _recall(self):\n",
    "        res = []\n",
    "        for i in range(self.num_classes):\n",
    "            temp = self.matrix[i][i] / (sum(self.matrix[i]) + self.epsilon)\n",
    "            res.append(temp)\n",
    "        return res\n",
    "\n",
    "    def _w_recall(self):\n",
    "        res = []\n",
    "        for i in range(self.num_classes):\n",
    "            w = self.weights[self.num_classes - 1 - i: self.num_classes*2 - 1 - i]\n",
    "            temp = 0\n",
    "            for j in range(self.num_classes):\n",
    "                temp += self.matrix[i][j] * w[j]\n",
    "            temp /= (sum(self.matrix[i]) + self.epsilon)\n",
    "            res.append(temp)\n",
    "        return res\n",
    "\n",
    "    def _p_recall(self):\n",
    "        res = []\n",
    "        for i in range(self.num_classes):\n",
    "            p = self.penalty[self.num_classes - 1 - i: self.num_classes*2 - 1 - i]\n",
    "            temp = 0\n",
    "            for j in range(self.num_classes):\n",
    "                temp += self.matrix[i][j] * p[j]\n",
    "            temp /= (sum(self.matrix[i]) + self.epsilon)\n",
    "            res.append(temp)\n",
    "        return res\n",
    "\n",
    "    def get_precision(self):\n",
    "        pre = self._precision()\n",
    "        return sum(pre)/len(pre)\n",
    "\n",
    "    def get_recall(self):\n",
    "        rec = self._recall()\n",
    "        return sum(rec)/len(rec)\n",
    "\n",
    "    def get_w_recall(self):\n",
    "        wrec = self._w_recall()\n",
    "        return sum(wrec)/len(wrec)\n",
    "\n",
    "    def get_p_recall(self):\n",
    "        prec = self._p_recall()\n",
    "        return sum(prec)/len(prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1/100] Model Saved. Best Accuracy: 0.30986\n",
      "[epoch 1/100] train_loss: 1.4149 train_accuracy: 0.42325 val_loss: 1.5589 val_accuracy: 0.30986\n",
      "[epoch 1/100] train_recall: 0.42818 train_wrecall: 0.5857 train_precall: 0.39848\n",
      "[epoch 1/100] valid_recall: 0.37165 valid_wrecall: 0.55569 valid_precall: 0.377\n",
      "[epoch 2/100] Model Saved. Best Accuracy: 0.45272\n",
      "[epoch 2/100] train_loss: 1.1578 train_accuracy: 0.59262 val_loss: 1.2839 val_accuracy: 0.45272\n",
      "[epoch 2/100] train_recall: 0.60195 train_wrecall: 0.74445 train_precall: 0.6793\n",
      "[epoch 2/100] valid_recall: 0.55539 valid_wrecall: 0.73926 valid_precall: 0.70083\n",
      "[epoch 3/100] Model Saved. Best Accuracy: 0.48692\n",
      "[epoch 3/100] train_loss: 1.0183 train_accuracy: 0.66125 val_loss: 1.2432 val_accuracy: 0.48692\n",
      "[epoch 3/100] train_recall: 0.65777 train_wrecall: 0.7855 train_precall: 0.73467\n",
      "[epoch 3/100] valid_recall: 0.57477 valid_wrecall: 0.7418 valid_precall: 0.69085\n",
      "[epoch 4/100] Model Saved. Best Accuracy: 0.56338\n",
      "[epoch 4/100] train_loss: 0.9498 train_accuracy: 0.71107 val_loss: 1.1701 val_accuracy: 0.56338\n",
      "[epoch 4/100] train_recall: 0.71624 train_wrecall: 0.82995 train_precall: 0.7995\n",
      "[epoch 4/100] valid_recall: 0.58041 valid_wrecall: 0.77008 valid_precall: 0.74947\n",
      "[epoch 5/100] train_loss: 0.90448 train_accuracy: 0.74096 val_loss: 1.2251 val_accuracy: 0.52918\n",
      "[epoch 5/100] train_recall: 0.74089 train_wrecall: 0.84461 train_precall: 0.81746\n",
      "[epoch 5/100] valid_recall: 0.59483 valid_wrecall: 0.77341 valid_precall: 0.7494\n",
      "[epoch 6/100] Model Saved. Best Accuracy: 0.60563\n",
      "[epoch 6/100] train_loss: 0.86945 train_accuracy: 0.77048 val_loss: 1.1338 val_accuracy: 0.60563\n",
      "[epoch 6/100] train_recall: 0.77532 train_wrecall: 0.86659 train_precall: 0.8444\n",
      "[epoch 6/100] valid_recall: 0.51649 valid_wrecall: 0.73892 valid_precall: 0.7196\n",
      "[epoch 7/100] Model Saved. Best Accuracy: 0.6499\n",
      "[epoch 7/100] train_loss: 0.83047 train_accuracy: 0.79668 val_loss: 1.0898 val_accuracy: 0.6499\n",
      "[epoch 7/100] train_recall: 0.79782 train_wrecall: 0.88278 train_precall: 0.86519\n",
      "[epoch 7/100] valid_recall: 0.59115 valid_wrecall: 0.78689 valid_precall: 0.77821\n",
      "[epoch 8/100] train_loss: 0.81875 train_accuracy: 0.80959 val_loss: 1.1937 val_accuracy: 0.53722\n",
      "[epoch 8/100] train_recall: 0.81192 train_wrecall: 0.89024 train_precall: 0.87341\n",
      "[epoch 8/100] valid_recall: 0.5259 valid_wrecall: 0.73552 valid_precall: 0.70809\n",
      "[epoch 9/100] train_loss: 0.77954 train_accuracy: 0.8321 val_loss: 1.1523 val_accuracy: 0.59155\n",
      "[epoch 9/100] train_recall: 0.83367 train_wrecall: 0.90481 train_precall: 0.89128\n",
      "[epoch 9/100] valid_recall: 0.56382 valid_wrecall: 0.76835 valid_precall: 0.75479\n",
      "[epoch 10/100] train_loss: 0.75626 train_accuracy: 0.84539 val_loss: 1.1073 val_accuracy: 0.61368\n",
      "[epoch 10/100] train_recall: 0.84697 train_wrecall: 0.91383 train_precall: 0.90418\n",
      "[epoch 10/100] valid_recall: 0.55598 valid_wrecall: 0.76497 valid_precall: 0.75196\n",
      "[epoch 11/100] train_loss: 0.7436 train_accuracy: 0.85018 val_loss: 1.1776 val_accuracy: 0.56338\n",
      "[epoch 11/100] train_recall: 0.85323 train_wrecall: 0.91824 train_precall: 0.90929\n",
      "[epoch 11/100] valid_recall: 0.54437 valid_wrecall: 0.73267 valid_precall: 0.69268\n",
      "[epoch 12/100] train_loss: 0.72058 train_accuracy: 0.87232 val_loss: 1.1237 val_accuracy: 0.60563\n",
      "[epoch 12/100] train_recall: 0.87318 train_wrecall: 0.9302 train_precall: 0.92306\n",
      "[epoch 12/100] valid_recall: 0.51089 valid_wrecall: 0.74676 valid_precall: 0.73807\n",
      "[epoch 13/100] train_loss: 0.69136 train_accuracy: 0.88339 val_loss: 1.1531 val_accuracy: 0.61972\n",
      "[epoch 13/100] train_recall: 0.88345 train_wrecall: 0.93606 train_precall: 0.92984\n",
      "[epoch 13/100] valid_recall: 0.49309 valid_wrecall: 0.73486 valid_precall: 0.72318\n",
      "[epoch 14/100] train_loss: 0.70694 train_accuracy: 0.87232 val_loss: 1.1616 val_accuracy: 0.62374\n",
      "[epoch 14/100] train_recall: 0.87583 train_wrecall: 0.93187 train_precall: 0.92489\n",
      "[epoch 14/100] valid_recall: 0.57211 valid_wrecall: 0.78175 valid_precall: 0.77744\n",
      "[epoch 15/100] train_loss: 0.68016 train_accuracy: 0.89336 val_loss: 1.1284 val_accuracy: 0.61972\n",
      "[epoch 15/100] train_recall: 0.8967 train_wrecall: 0.94264 train_precall: 0.93564\n",
      "[epoch 15/100] valid_recall: 0.51112 valid_wrecall: 0.7434 valid_precall: 0.73124\n",
      "[epoch 16/100] train_loss: 0.66841 train_accuracy: 0.89114 val_loss: 1.1834 val_accuracy: 0.61771\n",
      "[epoch 16/100] train_recall: 0.89201 train_wrecall: 0.94029 train_precall: 0.93401\n",
      "[epoch 16/100] valid_recall: 0.5522 valid_wrecall: 0.75564 valid_precall: 0.73518\n",
      "[epoch 17/100] train_loss: 0.64976 train_accuracy: 0.91402 val_loss: 1.2743 val_accuracy: 0.56137\n",
      "[epoch 17/100] train_recall: 0.91577 train_wrecall: 0.95361 train_precall: 0.94877\n",
      "[epoch 17/100] valid_recall: 0.53123 valid_wrecall: 0.72808 valid_precall: 0.69054\n",
      "[epoch 18/100] train_loss: 0.6453 train_accuracy: 0.91144 val_loss: 1.2427 val_accuracy: 0.5996\n",
      "[epoch 18/100] train_recall: 0.91548 train_wrecall: 0.95228 train_precall: 0.94644\n",
      "[epoch 18/100] valid_recall: 0.52478 valid_wrecall: 0.72666 valid_precall: 0.69094\n",
      "[epoch 19/100] train_loss: 0.62491 train_accuracy: 0.931 val_loss: 1.1675 val_accuracy: 0.6338\n",
      "[epoch 19/100] train_recall: 0.9311 train_wrecall: 0.96363 train_precall: 0.96172\n",
      "[epoch 19/100] valid_recall: 0.52933 valid_wrecall: 0.76371 valid_precall: 0.76276\n",
      "[epoch 20/100] train_loss: 0.6166 train_accuracy: 0.93395 val_loss: 1.2619 val_accuracy: 0.63984\n",
      "[epoch 20/100] train_recall: 0.93522 train_wrecall: 0.96438 train_precall: 0.96116\n",
      "[epoch 20/100] valid_recall: 0.56149 valid_wrecall: 0.76585 valid_precall: 0.75096\n",
      "[epoch 21/100] train_loss: 0.60727 train_accuracy: 0.93948 val_loss: 1.3225 val_accuracy: 0.61167\n",
      "[epoch 21/100] train_recall: 0.94271 train_wrecall: 0.96898 train_precall: 0.96623\n",
      "[epoch 21/100] valid_recall: 0.53025 valid_wrecall: 0.74832 valid_precall: 0.73151\n",
      "[epoch 22/100] train_loss: 0.59984 train_accuracy: 0.94391 val_loss: 1.2888 val_accuracy: 0.61368\n",
      "[epoch 22/100] train_recall: 0.94692 train_wrecall: 0.97035 train_precall: 0.96706\n",
      "[epoch 22/100] valid_recall: 0.51977 valid_wrecall: 0.74215 valid_precall: 0.72441\n",
      "[epoch 23/100] train_loss: 0.58604 train_accuracy: 0.95129 val_loss: 1.237 val_accuracy: 0.61771\n",
      "[epoch 23/100] train_recall: 0.95353 train_wrecall: 0.97473 train_precall: 0.97233\n",
      "[epoch 23/100] valid_recall: 0.50423 valid_wrecall: 0.71198 valid_precall: 0.65935\n",
      "[epoch 24/100] train_loss: 0.59078 train_accuracy: 0.94354 val_loss: 1.3066 val_accuracy: 0.60966\n",
      "[epoch 24/100] train_recall: 0.9449 train_wrecall: 0.9706 train_precall: 0.96839\n",
      "[epoch 24/100] valid_recall: 0.51215 valid_wrecall: 0.71787 valid_precall: 0.67967\n",
      "[epoch 25/100] train_loss: 0.58006 train_accuracy: 0.95277 val_loss: 1.4059 val_accuracy: 0.55936\n",
      "[epoch 25/100] train_recall: 0.95382 train_wrecall: 0.97523 train_precall: 0.97319\n",
      "[epoch 25/100] valid_recall: 0.49397 valid_wrecall: 0.72147 valid_precall: 0.68345\n",
      "[epoch 26/100] train_loss: 0.5768 train_accuracy: 0.95314 val_loss: 1.2226 val_accuracy: 0.63581\n",
      "[epoch 26/100] train_recall: 0.95429 train_wrecall: 0.97601 train_precall: 0.97487\n",
      "[epoch 26/100] valid_recall: 0.50631 valid_wrecall: 0.72993 valid_precall: 0.70671\n",
      "[epoch 27/100] train_loss: 0.57137 train_accuracy: 0.95793 val_loss: 1.2828 val_accuracy: 0.5835\n",
      "[epoch 27/100] train_recall: 0.95934 train_wrecall: 0.97816 train_precall: 0.97666\n",
      "[epoch 27/100] valid_recall: 0.51787 valid_wrecall: 0.73382 valid_precall: 0.69621\n",
      "[epoch 28/100] train_loss: 0.56119 train_accuracy: 0.96531 val_loss: 1.3746 val_accuracy: 0.61167\n",
      "[epoch 28/100] train_recall: 0.96758 train_wrecall: 0.98305 train_precall: 0.98231\n",
      "[epoch 28/100] valid_recall: 0.48862 valid_wrecall: 0.72501 valid_precall: 0.70572\n",
      "[epoch 29/100] train_loss: 0.55442 train_accuracy: 0.96679 val_loss: 1.2522 val_accuracy: 0.60362\n",
      "[epoch 29/100] train_recall: 0.96857 train_wrecall: 0.9826 train_precall: 0.98072\n",
      "[epoch 29/100] valid_recall: 0.49116 valid_wrecall: 0.7008 valid_precall: 0.65603\n",
      "[epoch 30/100] train_loss: 0.56968 train_accuracy: 0.9572 val_loss: 1.3134 val_accuracy: 0.5996\n",
      "[epoch 30/100] train_recall: 0.95951 train_wrecall: 0.97824 train_precall: 0.97673\n",
      "[epoch 30/100] valid_recall: 0.4969 valid_wrecall: 0.71464 valid_precall: 0.68083\n",
      "[epoch 31/100] train_loss: 0.5617 train_accuracy: 0.9631 val_loss: 1.4038 val_accuracy: 0.60765\n",
      "[epoch 31/100] train_recall: 0.96551 train_wrecall: 0.98026 train_precall: 0.9776\n",
      "[epoch 31/100] valid_recall: 0.50479 valid_wrecall: 0.70907 valid_precall: 0.66574\n",
      "[epoch 32/100] train_loss: 0.54805 train_accuracy: 0.96937 val_loss: 1.3104 val_accuracy: 0.60966\n",
      "[epoch 32/100] train_recall: 0.97169 train_wrecall: 0.98437 train_precall: 0.9827\n",
      "[epoch 32/100] valid_recall: 0.5119 valid_wrecall: 0.73867 valid_precall: 0.72138\n",
      "[epoch 33/100] train_loss: 0.54582 train_accuracy: 0.96974 val_loss: 1.3569 val_accuracy: 0.62777\n",
      "[epoch 33/100] train_recall: 0.97218 train_wrecall: 0.98479 train_precall: 0.98349\n",
      "[epoch 33/100] valid_recall: 0.52621 valid_wrecall: 0.71488 valid_precall: 0.66666\n",
      "[epoch 34/100] train_loss: 0.5558 train_accuracy: 0.96347 val_loss: 1.4648 val_accuracy: 0.55734\n",
      "[epoch 34/100] train_recall: 0.96694 train_wrecall: 0.98165 train_precall: 0.97945\n",
      "[epoch 34/100] valid_recall: 0.49909 valid_wrecall: 0.69045 valid_precall: 0.63136\n",
      "[epoch 35/100] train_loss: 0.53986 train_accuracy: 0.97454 val_loss: 1.3866 val_accuracy: 0.58551\n",
      "[epoch 35/100] train_recall: 0.97633 train_wrecall: 0.98705 train_precall: 0.98593\n",
      "[epoch 35/100] valid_recall: 0.51267 valid_wrecall: 0.7042 valid_precall: 0.65207\n",
      "[epoch 36/100] train_loss: 0.54614 train_accuracy: 0.97085 val_loss: 1.2435 val_accuracy: 0.64588\n",
      "[epoch 36/100] train_recall: 0.97337 train_wrecall: 0.98578 train_precall: 0.98487\n",
      "[epoch 36/100] valid_recall: 0.50518 valid_wrecall: 0.73819 valid_precall: 0.72378\n",
      "[epoch 37/100] train_loss: 0.5428 train_accuracy: 0.97528 val_loss: 1.2789 val_accuracy: 0.61167\n",
      "[epoch 37/100] train_recall: 0.97731 train_wrecall: 0.98828 train_precall: 0.98791\n",
      "[epoch 37/100] valid_recall: 0.49484 valid_wrecall: 0.71861 valid_precall: 0.6898\n",
      "[epoch 38/100] train_loss: 0.53548 train_accuracy: 0.97122 val_loss: 1.4436 val_accuracy: 0.59557\n",
      "[epoch 38/100] train_recall: 0.9732 train_wrecall: 0.98549 train_precall: 0.98419\n",
      "[epoch 38/100] valid_recall: 0.49303 valid_wrecall: 0.70616 valid_precall: 0.6658\n",
      "[epoch 39/100] train_loss: 0.53318 train_accuracy: 0.97528 val_loss: 1.2969 val_accuracy: 0.62173\n",
      "[epoch 39/100] train_recall: 0.97741 train_wrecall: 0.98741 train_precall: 0.98592\n",
      "[epoch 39/100] valid_recall: 0.48765 valid_wrecall: 0.71299 valid_precall: 0.68215\n",
      "[epoch 40/100] train_loss: 0.52787 train_accuracy: 0.97675 val_loss: 1.3841 val_accuracy: 0.62978\n",
      "[epoch 40/100] train_recall: 0.97912 train_wrecall: 0.98899 train_precall: 0.98805\n",
      "[epoch 40/100] valid_recall: 0.52722 valid_wrecall: 0.74527 valid_precall: 0.72693\n",
      "[epoch 41/100] train_loss: 0.52779 train_accuracy: 0.97786 val_loss: 1.3667 val_accuracy: 0.61167\n",
      "[epoch 41/100] train_recall: 0.97994 train_wrecall: 0.98922 train_precall: 0.98846\n",
      "[epoch 41/100] valid_recall: 0.4769 valid_wrecall: 0.70321 valid_precall: 0.66796\n",
      "[epoch 42/100] train_loss: 0.52731 train_accuracy: 0.97601 val_loss: 1.3076 val_accuracy: 0.60161\n",
      "[epoch 42/100] train_recall: 0.97805 train_wrecall: 0.98792 train_precall: 0.98646\n",
      "[epoch 42/100] valid_recall: 0.4846 valid_wrecall: 0.72504 valid_precall: 0.70778\n",
      "[epoch 43/100] train_loss: 0.52188 train_accuracy: 0.98081 val_loss: 1.3443 val_accuracy: 0.59356\n",
      "[epoch 43/100] train_recall: 0.98357 train_wrecall: 0.99123 train_precall: 0.99067\n",
      "[epoch 43/100] valid_recall: 0.48052 valid_wrecall: 0.72345 valid_precall: 0.70665\n",
      "[epoch 44/100] train_loss: 0.52074 train_accuracy: 0.97934 val_loss: 1.27 val_accuracy: 0.64185\n",
      "[epoch 44/100] train_recall: 0.98174 train_wrecall: 0.99069 train_precall: 0.99032\n",
      "[epoch 44/100] valid_recall: 0.49733 valid_wrecall: 0.71736 valid_precall: 0.68605\n",
      "[epoch 45/100] train_loss: 0.5317 train_accuracy: 0.97491 val_loss: 1.357 val_accuracy: 0.62173\n",
      "[epoch 45/100] train_recall: 0.97751 train_wrecall: 0.98729 train_precall: 0.98564\n",
      "[epoch 45/100] valid_recall: 0.48731 valid_wrecall: 0.7028 valid_precall: 0.66195\n",
      "[epoch 46/100] train_loss: 0.52066 train_accuracy: 0.97934 val_loss: 1.2893 val_accuracy: 0.59356\n",
      "[epoch 46/100] train_recall: 0.98163 train_wrecall: 0.98951 train_precall: 0.98783\n",
      "[epoch 46/100] valid_recall: 0.51027 valid_wrecall: 0.72238 valid_precall: 0.68962\n",
      "[epoch 47/100] train_loss: 0.51625 train_accuracy: 0.98192 val_loss: 1.3331 val_accuracy: 0.60563\n",
      "[epoch 47/100] train_recall: 0.98418 train_wrecall: 0.99154 train_precall: 0.9908\n",
      "[epoch 47/100] valid_recall: 0.49768 valid_wrecall: 0.71954 valid_precall: 0.69023\n",
      "[epoch 48/100] train_loss: 0.51848 train_accuracy: 0.97934 val_loss: 1.2695 val_accuracy: 0.61569\n",
      "[epoch 48/100] train_recall: 0.98147 train_wrecall: 0.98998 train_precall: 0.98922\n",
      "[epoch 48/100] valid_recall: 0.49097 valid_wrecall: 0.73013 valid_precall: 0.71477\n",
      "[epoch 49/100] train_loss: 0.51822 train_accuracy: 0.98192 val_loss: 1.4559 val_accuracy: 0.57948\n",
      "[epoch 49/100] train_recall: 0.98471 train_wrecall: 0.99218 train_precall: 0.992\n",
      "[epoch 49/100] valid_recall: 0.49754 valid_wrecall: 0.71659 valid_precall: 0.68442\n",
      "[epoch 50/100] train_loss: 0.50982 train_accuracy: 0.98635 val_loss: 1.4311 val_accuracy: 0.60563\n",
      "[epoch 50/100] train_recall: 0.98863 train_wrecall: 0.99414 train_precall: 0.99378\n",
      "[epoch 50/100] valid_recall: 0.48548 valid_wrecall: 0.70285 valid_precall: 0.66296\n",
      "[epoch 51/100] train_loss: 0.51132 train_accuracy: 0.9845 val_loss: 1.4258 val_accuracy: 0.55131\n",
      "[epoch 51/100] train_recall: 0.98657 train_wrecall: 0.9931 train_precall: 0.99291\n",
      "[epoch 51/100] valid_recall: 0.50301 valid_wrecall: 0.71508 valid_precall: 0.67865\n",
      "[epoch 52/100] train_loss: 0.51148 train_accuracy: 0.98524 val_loss: 1.4029 val_accuracy: 0.5996\n",
      "[epoch 52/100] train_recall: 0.98762 train_wrecall: 0.99311 train_precall: 0.9924\n",
      "[epoch 52/100] valid_recall: 0.47673 valid_wrecall: 0.6956 valid_precall: 0.65284\n",
      "[epoch 53/100] train_loss: 0.51555 train_accuracy: 0.98229 val_loss: 1.2776 val_accuracy: 0.63984\n",
      "[epoch 53/100] train_recall: 0.98464 train_wrecall: 0.99105 train_precall: 0.98977\n",
      "[epoch 53/100] valid_recall: 0.49584 valid_wrecall: 0.71957 valid_precall: 0.69122\n",
      "[epoch 54/100] train_loss: 0.51353 train_accuracy: 0.98155 val_loss: 1.3022 val_accuracy: 0.59155\n",
      "[epoch 54/100] train_recall: 0.98361 train_wrecall: 0.99107 train_precall: 0.99014\n",
      "[epoch 54/100] valid_recall: 0.48548 valid_wrecall: 0.71048 valid_precall: 0.67822\n",
      "[epoch 55/100] train_loss: 0.50892 train_accuracy: 0.98413 val_loss: 1.3664 val_accuracy: 0.59155\n",
      "[epoch 55/100] train_recall: 0.98639 train_wrecall: 0.99245 train_precall: 0.99171\n",
      "[epoch 55/100] valid_recall: 0.47865 valid_wrecall: 0.698 valid_precall: 0.65667\n",
      "[epoch 56/100] train_loss: 0.50406 train_accuracy: 0.98782 val_loss: 1.4015 val_accuracy: 0.58954\n",
      "[epoch 56/100] train_recall: 0.98999 train_wrecall: 0.99463 train_precall: 0.99426\n",
      "[epoch 56/100] valid_recall: 0.48971 valid_wrecall: 0.7121 valid_precall: 0.67934\n",
      "[epoch 57/100] train_loss: 0.49969 train_accuracy: 0.98967 val_loss: 1.3602 val_accuracy: 0.58551\n",
      "[epoch 57/100] train_recall: 0.99192 train_wrecall: 0.99522 train_precall: 0.99449\n",
      "[epoch 57/100] valid_recall: 0.47047 valid_wrecall: 0.69488 valid_precall: 0.65452\n",
      "[epoch 58/100] train_loss: 0.50383 train_accuracy: 0.98672 val_loss: 1.3831 val_accuracy: 0.59557\n",
      "[epoch 58/100] train_recall: 0.98898 train_wrecall: 0.99412 train_precall: 0.99375\n",
      "[epoch 58/100] valid_recall: 0.4689 valid_wrecall: 0.71669 valid_precall: 0.69892\n",
      "[epoch 59/100] train_loss: 0.51139 train_accuracy: 0.9797 val_loss: 1.3123 val_accuracy: 0.62978\n",
      "[epoch 59/100] train_recall: 0.98189 train_wrecall: 0.99039 train_precall: 0.98965\n",
      "[epoch 59/100] valid_recall: 0.49111 valid_wrecall: 0.72923 valid_precall: 0.7129\n",
      "[epoch 60/100] train_loss: 0.50584 train_accuracy: 0.98708 val_loss: 1.4088 val_accuracy: 0.57344\n",
      "[epoch 60/100] train_recall: 0.98919 train_wrecall: 0.99422 train_precall: 0.99366\n",
      "[epoch 60/100] valid_recall: 0.47683 valid_wrecall: 0.7003 valid_precall: 0.66218\n",
      "[epoch 61/100] train_loss: 0.49395 train_accuracy: 0.99262 val_loss: 1.4987 val_accuracy: 0.54326\n",
      "[epoch 61/100] train_recall: 0.99478 train_wrecall: 0.99721 train_precall: 0.99703\n",
      "[epoch 61/100] valid_recall: 0.46812 valid_wrecall: 0.70093 valid_precall: 0.66779\n",
      "[epoch 62/100] train_loss: 0.50199 train_accuracy: 0.98856 val_loss: 1.3012 val_accuracy: 0.60765\n",
      "[epoch 62/100] train_recall: 0.99088 train_wrecall: 0.99506 train_precall: 0.99447\n",
      "[epoch 62/100] valid_recall: 0.48689 valid_wrecall: 0.72166 valid_precall: 0.69987\n",
      "[epoch 63/100] train_loss: 0.50433 train_accuracy: 0.98708 val_loss: 1.3518 val_accuracy: 0.5996\n",
      "[epoch 63/100] train_recall: 0.98956 train_wrecall: 0.99478 train_precall: 0.99478\n",
      "[epoch 63/100] valid_recall: 0.4767 valid_wrecall: 0.69798 valid_precall: 0.65761\n",
      "[epoch 64/100] train_loss: 0.5019 train_accuracy: 0.98856 val_loss: 1.3399 val_accuracy: 0.59155\n",
      "[epoch 64/100] train_recall: 0.99087 train_wrecall: 0.99489 train_precall: 0.99434\n",
      "[epoch 64/100] valid_recall: 0.48552 valid_wrecall: 0.71252 valid_precall: 0.68228\n",
      "[epoch 65/100] train_loss: 0.49733 train_accuracy: 0.99151 val_loss: 1.4018 val_accuracy: 0.56338\n",
      "[epoch 65/100] train_recall: 0.99379 train_wrecall: 0.99654 train_precall: 0.99618\n",
      "[epoch 65/100] valid_recall: 0.48984 valid_wrecall: 0.7137 valid_precall: 0.68248\n",
      "[epoch 66/100] train_loss: 0.50207 train_accuracy: 0.98708 val_loss: 1.3391 val_accuracy: 0.58551\n",
      "[epoch 66/100] train_recall: 0.98935 train_wrecall: 0.99411 train_precall: 0.99355\n",
      "[epoch 66/100] valid_recall: 0.50046 valid_wrecall: 0.74499 valid_precall: 0.73975\n",
      "[epoch 67/100] train_loss: 0.49999 train_accuracy: 0.98672 val_loss: 1.2605 val_accuracy: 0.5996\n",
      "[epoch 67/100] train_recall: 0.98876 train_wrecall: 0.99363 train_precall: 0.99288\n",
      "[epoch 67/100] valid_recall: 0.48895 valid_wrecall: 0.71614 valid_precall: 0.68781\n",
      "[epoch 68/100] train_loss: 0.49399 train_accuracy: 0.99188 val_loss: 1.3809 val_accuracy: 0.59155\n",
      "[epoch 68/100] train_recall: 0.99415 train_wrecall: 0.99669 train_precall: 0.99612\n",
      "[epoch 68/100] valid_recall: 0.48523 valid_wrecall: 0.71179 valid_precall: 0.68096\n",
      "[epoch 69/100] train_loss: 0.495 train_accuracy: 0.99114 val_loss: 1.3195 val_accuracy: 0.59557\n",
      "[epoch 69/100] train_recall: 0.99345 train_wrecall: 0.99598 train_precall: 0.99505\n",
      "[epoch 69/100] valid_recall: 0.49446 valid_wrecall: 0.70092 valid_precall: 0.65461\n",
      "[epoch 70/100] train_loss: 0.49168 train_accuracy: 0.99225 val_loss: 1.3718 val_accuracy: 0.57948\n",
      "[epoch 70/100] train_recall: 0.99452 train_wrecall: 0.99708 train_precall: 0.9969\n",
      "[epoch 70/100] valid_recall: 0.47954 valid_wrecall: 0.70905 valid_precall: 0.67834\n",
      "[epoch 71/100] train_loss: 0.49108 train_accuracy: 0.99262 val_loss: 1.2968 val_accuracy: 0.59557\n",
      "[epoch 71/100] train_recall: 0.9949 train_wrecall: 0.99707 train_precall: 0.99669\n",
      "[epoch 71/100] valid_recall: 0.48135 valid_wrecall: 0.69794 valid_precall: 0.6552\n",
      "[epoch 72/100] train_loss: 0.49785 train_accuracy: 0.98598 val_loss: 1.445 val_accuracy: 0.57545\n",
      "[epoch 72/100] train_recall: 0.98794 train_wrecall: 0.99362 train_precall: 0.99309\n",
      "[epoch 72/100] valid_recall: 0.45296 valid_wrecall: 0.67361 valid_precall: 0.62074\n",
      "[epoch 73/100] train_loss: 0.4935 train_accuracy: 0.99077 val_loss: 1.4434 val_accuracy: 0.55533\n",
      "[epoch 73/100] train_recall: 0.99296 train_wrecall: 0.9963 train_precall: 0.99611\n",
      "[epoch 73/100] valid_recall: 0.47989 valid_wrecall: 0.68372 valid_precall: 0.6275\n",
      "[epoch 74/100] train_loss: 0.49708 train_accuracy: 0.98967 val_loss: 1.3882 val_accuracy: 0.57344\n",
      "[epoch 74/100] train_recall: 0.99185 train_wrecall: 0.99556 train_precall: 0.99519\n",
      "[epoch 74/100] valid_recall: 0.48902 valid_wrecall: 0.71285 valid_precall: 0.68118\n",
      "[epoch 75/100] train_loss: 0.49368 train_accuracy: 0.99114 val_loss: 1.3367 val_accuracy: 0.58954\n",
      "[epoch 75/100] train_recall: 0.99337 train_wrecall: 0.99632 train_precall: 0.99596\n",
      "[epoch 75/100] valid_recall: 0.46606 valid_wrecall: 0.67623 valid_precall: 0.61943\n",
      "[epoch 76/100] train_loss: 0.49531 train_accuracy: 0.98856 val_loss: 1.3079 val_accuracy: 0.59356\n",
      "[epoch 76/100] train_recall: 0.99072 train_wrecall: 0.99481 train_precall: 0.99406\n",
      "[epoch 76/100] valid_recall: 0.47442 valid_wrecall: 0.69876 valid_precall: 0.66031\n",
      "[epoch 77/100] train_loss: 0.49213 train_accuracy: 0.99004 val_loss: 1.3671 val_accuracy: 0.57545\n",
      "[epoch 77/100] train_recall: 0.99206 train_wrecall: 0.99548 train_precall: 0.99476\n",
      "[epoch 77/100] valid_recall: 0.50144 valid_wrecall: 0.70451 valid_precall: 0.6583\n",
      "[epoch 78/100] train_loss: 0.49117 train_accuracy: 0.99077 val_loss: 1.4713 val_accuracy: 0.56539\n",
      "[epoch 78/100] train_recall: 0.99286 train_wrecall: 0.99643 train_precall: 0.99643\n",
      "[epoch 78/100] valid_recall: 0.46682 valid_wrecall: 0.69056 valid_precall: 0.6477\n",
      "[epoch 79/100] train_loss: 0.48984 train_accuracy: 0.99262 val_loss: 1.4318 val_accuracy: 0.55533\n",
      "[epoch 79/100] train_recall: 0.99483 train_wrecall: 0.99685 train_precall: 0.9961\n",
      "[epoch 79/100] valid_recall: 0.4685 valid_wrecall: 0.69913 valid_precall: 0.66402\n",
      "[epoch 80/100] train_loss: 0.49477 train_accuracy: 0.98745 val_loss: 1.3561 val_accuracy: 0.60765\n",
      "[epoch 80/100] train_recall: 0.98951 train_wrecall: 0.99475 train_precall: 0.99475\n",
      "[epoch 80/100] valid_recall: 0.48163 valid_wrecall: 0.70534 valid_precall: 0.66986\n",
      "[epoch 81/100] train_loss: 0.4913 train_accuracy: 0.98967 val_loss: 1.5177 val_accuracy: 0.52314\n",
      "[epoch 81/100] train_recall: 0.99171 train_wrecall: 0.99567 train_precall: 0.99548\n",
      "[epoch 81/100] valid_recall: 0.48921 valid_wrecall: 0.69472 valid_precall: 0.64484\n",
      "[epoch 82/100] train_loss: 0.5055 train_accuracy: 0.98266 val_loss: 1.4072 val_accuracy: 0.5493\n",
      "[epoch 82/100] train_recall: 0.98546 train_wrecall: 0.99236 train_precall: 0.99179\n",
      "[epoch 82/100] valid_recall: 0.47094 valid_wrecall: 0.7008 valid_precall: 0.66613\n",
      "[epoch 83/100] train_loss: 0.48796 train_accuracy: 0.99299 val_loss: 1.5676 val_accuracy: 0.5171\n",
      "[epoch 83/100] train_recall: 0.9951 train_wrecall: 0.99736 train_precall: 0.99716\n",
      "[epoch 83/100] valid_recall: 0.47971 valid_wrecall: 0.69422 valid_precall: 0.64859\n",
      "[epoch 84/100] train_loss: 0.48754 train_accuracy: 0.99299 val_loss: 1.3961 val_accuracy: 0.55936\n",
      "[epoch 84/100] train_recall: 0.99517 train_wrecall: 0.99722 train_precall: 0.99687\n",
      "[epoch 84/100] valid_recall: 0.47613 valid_wrecall: 0.70629 valid_precall: 0.6745\n",
      "[epoch 85/100] train_loss: 0.48454 train_accuracy: 0.99262 val_loss: 1.3224 val_accuracy: 0.59155\n",
      "[epoch 85/100] train_recall: 0.99468 train_wrecall: 0.99734 train_precall: 0.99734\n",
      "[epoch 85/100] valid_recall: 0.46756 valid_wrecall: 0.71593 valid_precall: 0.69807\n",
      "[epoch 86/100] train_loss: 0.48754 train_accuracy: 0.99114 val_loss: 1.31 val_accuracy: 0.60563\n",
      "[epoch 86/100] train_recall: 0.99338 train_wrecall: 0.99613 train_precall: 0.99539\n",
      "[epoch 86/100] valid_recall: 0.47989 valid_wrecall: 0.7091 valid_precall: 0.67826\n",
      "[epoch 87/100] train_loss: 0.49231 train_accuracy: 0.9893 val_loss: 1.4096 val_accuracy: 0.57545\n",
      "[epoch 87/100] train_recall: 0.99137 train_wrecall: 0.99532 train_precall: 0.99495\n",
      "[epoch 87/100] valid_recall: 0.46587 valid_wrecall: 0.69067 valid_precall: 0.64841\n",
      "[epoch 88/100] train_loss: 0.49238 train_accuracy: 0.98967 val_loss: 1.367 val_accuracy: 0.5996\n",
      "[epoch 88/100] train_recall: 0.99168 train_wrecall: 0.99528 train_precall: 0.99452\n",
      "[epoch 88/100] valid_recall: 0.50123 valid_wrecall: 0.72131 valid_precall: 0.692\n",
      "[epoch 89/100] train_loss: 0.48822 train_accuracy: 0.99151 val_loss: 1.368 val_accuracy: 0.57746\n",
      "[epoch 89/100] train_recall: 0.99372 train_wrecall: 0.99631 train_precall: 0.99576\n",
      "[epoch 89/100] valid_recall: 0.46091 valid_wrecall: 0.68617 valid_precall: 0.64189\n",
      "[epoch 90/100] train_loss: 0.49244 train_accuracy: 0.98967 val_loss: 1.2247 val_accuracy: 0.6338\n",
      "[epoch 90/100] train_recall: 0.99196 train_wrecall: 0.99543 train_precall: 0.99488\n",
      "[epoch 90/100] valid_recall: 0.48165 valid_wrecall: 0.74035 valid_precall: 0.73987\n",
      "[epoch 91/100] train_loss: 0.48399 train_accuracy: 0.99299 val_loss: 1.3137 val_accuracy: 0.6338\n",
      "[epoch 91/100] train_recall: 0.99521 train_wrecall: 0.99742 train_precall: 0.99724\n",
      "[epoch 91/100] valid_recall: 0.49931 valid_wrecall: 0.70785 valid_precall: 0.66604\n",
      "[epoch 92/100] train_loss: 0.48826 train_accuracy: 0.99151 val_loss: 1.3095 val_accuracy: 0.62978\n",
      "[epoch 92/100] train_recall: 0.99378 train_wrecall: 0.99689 train_precall: 0.99689\n",
      "[epoch 92/100] valid_recall: 0.51569 valid_wrecall: 0.71654 valid_precall: 0.67523\n",
      "[epoch 93/100] train_loss: 0.4899 train_accuracy: 0.98856 val_loss: 1.3333 val_accuracy: 0.58753\n",
      "[epoch 93/100] train_recall: 0.99098 train_wrecall: 0.99549 train_precall: 0.99549\n",
      "[epoch 93/100] valid_recall: 0.49513 valid_wrecall: 0.69423 valid_precall: 0.6409\n",
      "[epoch 94/100] train_loss: 0.48868 train_accuracy: 0.99077 val_loss: 1.4476 val_accuracy: 0.58551\n",
      "[epoch 94/100] train_recall: 0.99306 train_wrecall: 0.99634 train_precall: 0.99616\n",
      "[epoch 94/100] valid_recall: 0.47599 valid_wrecall: 0.68321 valid_precall: 0.62843\n",
      "[epoch 95/100] train_loss: 0.4897 train_accuracy: 0.99041 val_loss: 1.4429 val_accuracy: 0.53722\n",
      "[epoch 95/100] train_recall: 0.99268 train_wrecall: 0.99559 train_precall: 0.99484\n",
      "[epoch 95/100] valid_recall: 0.47787 valid_wrecall: 0.70393 valid_precall: 0.66893\n",
      "[epoch 96/100] train_loss: 0.4876 train_accuracy: 0.99188 val_loss: 1.4139 val_accuracy: 0.58551\n",
      "[epoch 96/100] train_recall: 0.99409 train_wrecall: 0.99687 train_precall: 0.99669\n",
      "[epoch 96/100] valid_recall: 0.4526 valid_wrecall: 0.68345 valid_precall: 0.64059\n",
      "[epoch 97/100] train_loss: 0.48885 train_accuracy: 0.99151 val_loss: 1.3704 val_accuracy: 0.58753\n",
      "[epoch 97/100] train_recall: 0.99365 train_wrecall: 0.99682 train_precall: 0.99682\n",
      "[epoch 97/100] valid_recall: 0.48358 valid_wrecall: 0.71393 valid_precall: 0.68608\n",
      "[epoch 98/100] train_loss: 0.48251 train_accuracy: 0.99336 val_loss: 1.3868 val_accuracy: 0.5996\n",
      "[epoch 98/100] train_recall: 0.99552 train_wrecall: 0.99739 train_precall: 0.99701\n",
      "[epoch 98/100] valid_recall: 0.47706 valid_wrecall: 0.70972 valid_precall: 0.68091\n",
      "[epoch 99/100] train_loss: 0.48837 train_accuracy: 0.99004 val_loss: 1.5161 val_accuracy: 0.56539\n",
      "[epoch 99/100] train_recall: 0.99221 train_wrecall: 0.99553 train_precall: 0.99496\n",
      "[epoch 99/100] valid_recall: 0.44882 valid_wrecall: 0.65906 valid_precall: 0.5937\n",
      "[epoch 100/100] train_loss: 0.4856 train_accuracy: 0.99114 val_loss: 1.3527 val_accuracy: 0.5996\n",
      "[epoch 100/100] train_recall: 0.99323 train_wrecall: 0.99626 train_precall: 0.99591\n",
      "[epoch 100/100] valid_recall: 0.49481 valid_wrecall: 0.69966 valid_precall: 0.65191\n"
     ]
    }
   ],
   "source": [
    "total_train_image = len(train_dataset)                              # 총 학습 이미지의 개수를 의미한다.\n",
    "total_train_batch = len(train_loader)                               # 각 에포크 당 미니 배치 개수를 의미한다.\n",
    "total_val_image = len(valid_dataset)    \n",
    "total_val_batch = len(valid_loader)\n",
    "\n",
    "best_accuracy = 0\n",
    "for epoch in range(total_epoch):                                    # total_epoch 값 만큼 epoch 실행한다.\n",
    "  model.train()                                                     # model 학습 모드로 변경한다.\n",
    "  train_accuracy = 0                                                # 해당 epoch의 accuracy와 loss를 저장할 변수 선언한다.\n",
    "  train_loss = 0       \n",
    "  metric = Metric()                 \n",
    "  for images, labels in train_loader:   \n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    hypothesis = model(images)             \n",
    "    loss = criterion(hypothesis, labels)                                      \n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    prediction = torch.argmax(hypothesis, 1)                        # 학습 이미지에 대해 모델이 예측한 label을 저장한다.  \n",
    "    correct = (prediction == labels)                                # 정답 label들과 비교한다.\n",
    "    train_accuracy += correct.sum().item() / total_train_image      # accuracy 값을 갱신한다.\n",
    "    train_loss += loss.item() / total_train_batch                   # loss 값을 갱신한다.\n",
    "\n",
    "    metric.add_data(hypothesis, labels)\n",
    "  train_recall = metric.get_recall()\n",
    "  train_wrecall = metric.get_w_recall()\n",
    "  train_precall = metric.get_p_recall()\n",
    "\n",
    "  model.eval()\n",
    "  val_accuracy = 0\n",
    "  val_loss = 0\n",
    "  \n",
    "  with torch.no_grad():\n",
    "    model.eval()\n",
    "    metric = Metric()\n",
    "    for images, labels in valid_loader:\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "\n",
    "      hypothesis = model(images)\n",
    "      loss = criterion(hypothesis, labels)\n",
    "      \n",
    "      prediction = torch.argmax(hypothesis, 1)                        # 학습 이미지에 대해 모델이 예측한 label을 저장한다.                         \n",
    "      correct = (prediction == labels)\n",
    "      val_accuracy += correct.sum().item() / total_val_image\n",
    "      val_loss += loss.item() / total_val_batch\n",
    "\n",
    "      metric.add_data(hypothesis, labels)\n",
    "\n",
    "    valid_recall = metric.get_recall()\n",
    "    valid_wrecall = metric.get_w_recall()\n",
    "    valid_precall = metric.get_p_recall()\n",
    "\n",
    "    if best_accuracy < val_accuracy:\n",
    "      best_accuracy = val_accuracy\n",
    "      torch.save(model.state_dict(), f'model.pth')\n",
    "      print(f'[epoch {epoch+1}/{total_epoch}] Model Saved. Best Accuracy: {best_accuracy:.5}')\n",
    "    torch.save(model.state_dict(), f\"lastest.pth\")\n",
    "\n",
    "  print(f'[epoch {epoch+1}/{total_epoch}] train_loss: {train_loss:.5} train_accuracy: {train_accuracy:.5} val_loss: {val_loss:.5} val_accuracy: {val_accuracy:.5}')\n",
    "  print(f'[epoch {epoch+1}/{total_epoch}] train_recall: {train_recall:.5} train_wrecall: {train_wrecall:.5} train_precall: {train_precall:.5}')\n",
    "  print(f'[epoch {epoch+1}/{total_epoch}] valid_recall: {valid_recall:.5} valid_wrecall: {valid_wrecall:.5} valid_precall: {valid_precall:.5}')\n",
    "  with open('result.txt', 'a') as f:\n",
    "    f.write(f'[epoch {epoch+1}/{total_epoch}] train_loss: {train_loss:.5} train_accuracy: {train_accuracy:.5} val_loss: {val_loss:.5} val_accuracy: {val_accuracy:.5}\\n')\n",
    "    f.write(f'[epoch {epoch+1}/{total_epoch}] train_recall: {train_recall:.5} train_wrecall: {train_wrecall:.5} train_precall: {train_precall:.5}\\n')\n",
    "    f.write(f'[epoch {epoch+1}/{total_epoch}] valid_recall: {valid_recall:.5} valid_wrecall: {valid_wrecall:.5} valid_precall: {valid_precall:.5}\\n')\n",
    "    \n",
    "  wandb.log({\n",
    "    \"Train Loss\": train_loss,\n",
    "    \"Train Accuracy\": train_accuracy,\n",
    "    \"Train_recall\": train_recall,\n",
    "    \"Train_wrecall\": train_wrecall,\n",
    "    \"Train_precall\": train_precall,\n",
    "    \"Valid Loss\": val_loss,\n",
    "    \"Valid Accuracy\": val_accuracy,\n",
    "    \"Valid_recall\": valid_recall,\n",
    "    \"Valid_wrecall\": valid_wrecall,\n",
    "    \"Valid_precall\": valid_precall\n",
    "  })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Inference </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNet.from_pretrained('efficientnet-b0').to(device)\n",
    "\n",
    "in_features = model._fc.in_features\n",
    "model._fc = nn.Linear(in_features=in_features, out_features=5, bias=True).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('./base&offaug/latest.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_val_image = len(valid_dataset)\n",
    "total_val_batch = len(valid_loader)\n",
    "\n",
    "false_values = np.array([0 for _ in range(5)])      # 실제 라벨은 인덱스지만 다르게 예측한 경우\n",
    "true_values = np.array([0 for _ in range(5)])       # 실제 라벨을 정확히 예측한 경우\n",
    "prediction_values = np.array([0 for _ in range(5)]) # 예측한 값이 prediction의 개수 저장 / 즉 각 값은 각 label별 모델이 예측한 개수\n",
    "part_values = {}                                    # 정답 라벨별 예측 라벨의 개수 저장\n",
    "for i in range(5):\n",
    "    part_values[i] = np.array([0 for _ in range(5)])\n",
    "\n",
    "with torch.no_grad():\n",
    "    val_accuracy = 0\n",
    "    val_loss = 0\n",
    "    for images, labels in valid_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        label = labels[0].item()\n",
    "\n",
    "        prediction = model(images)\n",
    "        prediction = torch.argmax(prediction, 1)\n",
    "        prediction = prediction[0].item()\n",
    "        prediction_values[prediction] += 1\n",
    "        if prediction == label: true_values[label] += 1\n",
    "        else: false_values[label] += 1\n",
    "        part_values[label][prediction] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar([0, 1, 2, 3, 4], true_values+false_values)\n",
    "plt.bar([0, 1, 2, 3, 4], true_values)\n",
    "print(false_values)\n",
    "print(true_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar([0, 1, 2, 3, 4], prediction_values)\n",
    "plt.bar([0, 1, 2, 3, 4], true_values)\n",
    "print(prediction_values)\n",
    "print(true_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(part_values)\n",
    "sns.heatmap(df, annot=True, fmt='d')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "69b02c503323c0614d613512f26b2662d23fed04f2ba3d80045908c1dc3d71d0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
