{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from rembg import remove\n",
    "\n",
    "import torch\n",
    "import timm\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from torchsampler import ImbalancedDatasetSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "if device == 'cuda':\n",
    "  torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "pretrained_model = EfficientNet.from_pretrained('efficientnet-b0').to(device)\n",
    "\n",
    "in_features = pretrained_model._fc.in_features\n",
    "pretrained_model._fc = nn.Linear(in_features=in_features, out_features=5, bias=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_layers_list = []\n",
    "unshared_layers_list = []\n",
    "end_layer = 7\n",
    "\n",
    "type = 0 # 0: shared list에 저장 / 1: unshared_list에 저장\n",
    "for layer in pretrained_model.children():\n",
    "    if isinstance(layer, nn.ModuleList):                                            # nn.ModuleList에서 층을 나눠야 하므로 별도의 작업이 필요하다.\n",
    "        shared_modulelist_layers_list = []                                          # ModuleList에 저장된 층들 중 공유되어야 하는 층을 저장한다.\n",
    "        unshared_modulelist_layers_list = []                                        # ModuleList에 저장된 층들 중 공유되지 않는 층을 저장한다.\n",
    "        for index, modulelist_layer in enumerate(layer.children()):                 # 각 층을 탐색하면서 알맞은 리스트에 층을 저장한다.\n",
    "            if index <= end_layer:                                                  # 공유되어야 하는 층이라면 알맞은 리스트에 저장한다.\n",
    "                shared_modulelist_layers_list.append(modulelist_layer)\n",
    "            else:                                                                   # 비공유되어야 하는 층이라면 알맞은 리스트에 저장한다.\n",
    "                unshared_modulelist_layers_list.append(modulelist_layer)\n",
    "        shared_modulelist_layers = nn.ModuleList(shared_modulelist_layers_list)     # 각 리스트에 저장된 층들을 ModuleList에 저장해 알맞은 list에 append한다.\n",
    "        shared_layers_list.append(shared_modulelist_layers)\n",
    "        unshared_modulelist_layers = nn.ModuleList(unshared_modulelist_layers_list)\n",
    "        unshared_layers_list.append(unshared_modulelist_layers)\n",
    "        type = 1                                                                    # 이후에 나오는 층들은 unshared list에 저장해야 하므로 type 값을 1로 변경한다.\n",
    "        continue \n",
    "    \n",
    "    if type == 0: shared_layers_list.append(layer)\n",
    "    elif type == 1: unshared_layers_list.append(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNet_B0(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.shared_layers = nn.Sequential(\n",
    "            *shared_layers_list\n",
    "        )\n",
    "\n",
    "        self.oil = nn.Sequential(\n",
    "            *unshared_layers_list\n",
    "        )\n",
    "    \n",
    "        self.sensitive = nn.Sequential(\n",
    "            *unshared_layers_list\n",
    "        )\n",
    "\n",
    "        self.pigmentation = nn.Sequential(\n",
    "            *unshared_layers_list\n",
    "        )\n",
    "\n",
    "        self.wrinkle = nn.Sequential(\n",
    "            *unshared_layers_list\n",
    "        )\n",
    "\n",
    "        self.hydration = nn.Sequential(\n",
    "            *unshared_layers_list\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        shared_output = self.shared_layers(input)\n",
    "        oil = self.oil(shared_output)\n",
    "        sensitive = self.sensitive(shared_output)\n",
    "        pigmentation = self.pigmentation(shared_output)\n",
    "        wrinkle = self.wrinkle(shared_output)\n",
    "        hydration = self.hydration(shared_output)\n",
    "\n",
    "        return oil, sensitive, pigmentation, wrinkle, hydration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNet_B0()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "69b02c503323c0614d613512f26b2662d23fed04f2ba3d80045908c1dc3d71d0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('serving')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
